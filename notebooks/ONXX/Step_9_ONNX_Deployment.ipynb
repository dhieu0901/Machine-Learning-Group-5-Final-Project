{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e51401e",
      "metadata": {
        "id": "9e51401e"
      },
      "source": [
        "# Step 9: Improving Deployment Efficiency with ONNX\n",
        "\n",
        "## 9.1 The Challenge: From Research to Production\n",
        "\n",
        "After successfully developing, training, and evaluating our temperature forecasting model, the final step is to transition it from a research environment (like this notebook) to a live, production application. This process, known as **model deployment**, presents several critical challenges:\n",
        "\n",
        "*   **Dependency and Integration Complexity:** Our model was trained using the CatBoost library in a Python environment. Deploying it requires replicating these dependencies in a production server, which can be complex and might conflict with existing technology stacks (e.g., a web server running on Java or C#).\n",
        "*   **Performance and Scalability:** Production systems demand fast inference speed (low latency) and the ability to handle many simultaneous requests (high throughput). Standard model formats are often not optimized for these requirements.\n",
        "*   **Hardware and Platform Diversity:** A model may need to run on various systems, from high-performance cloud GPUs to resource-limited edge devices. The original model format is not inherently optimized for such diverse hardware.\n",
        "\n",
        "To address these challenges, we will use **ONNX (Open Neural Network Exchange)**. ONNX is an open-source format that provides a standardized representation of machine learning models. By converting our model to ONNX, we can achieve a portable, high-performance asset ready for robust deployment.\n",
        "\n",
        "## 9.2 Environment Setup and Imports\n",
        "\n",
        "First, let's set up the environment by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VoAYzXIbnAxf",
      "metadata": {
        "id": "VoAYzXIbnAxf"
      },
      "outputs": [],
      "source": [
        "# %pip install onnx onnxruntime scikit-learn==1.2.2 catboost joblib numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "23fd24da",
      "metadata": {
        "id": "23fd24da"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jinja2\n",
        "\n",
        "import onnx\n",
        "import onnxruntime as rt\n",
        "\n",
        "import timeit  # To benchmark performance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b70755e8",
      "metadata": {
        "id": "b70755e8"
      },
      "source": [
        "## 9.3 ONNX Application to Hanoi Temperature Forecasting Project\n",
        "\n",
        "In this section, we apply the ONNX conversion process to both our **Daily** and **Hourly** forecasting models. This will allow us to compare the performance gains across models of different complexities.\n",
        "\n",
        "### 9.3.1 Loading All Pre-trained Models and Test Data\n",
        "\n",
        "We begin by loading our two champion models (CatBoost trained on daily data and CatBoost trained on hourly data) and their corresponding preprocessed test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1659e0d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "1659e0d1",
        "outputId": "31cd9126-b791-451d-9ca1-15f06595fa6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded Hourly model and data. Shape: (514, 114)\n",
            "Successfully loaded Daily model and data. Shape: (549, 93)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp</th>\n",
              "      <th>precipprob</th>\n",
              "      <th>windgust</th>\n",
              "      <th>winddir</th>\n",
              "      <th>visibility</th>\n",
              "      <th>day_sin</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>season_Fall</th>\n",
              "      <th>temp_trend_yearly</th>\n",
              "      <th>...</th>\n",
              "      <th>humidity_rolling_last_12h</th>\n",
              "      <th>precip_rolling_last_3h</th>\n",
              "      <th>precip_rolling_last_9h</th>\n",
              "      <th>precip_rolling_last_15h</th>\n",
              "      <th>precipprob_rolling_last_9h</th>\n",
              "      <th>precipprob_rolling_last_15h</th>\n",
              "      <th>windspeed_rolling_last_6h</th>\n",
              "      <th>uvindex_rolling_last_3h</th>\n",
              "      <th>uvindex_rolling_last_6h</th>\n",
              "      <th>uvindex_rolling_last_18h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-04-27</th>\n",
              "      <td>32.195833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.345833</td>\n",
              "      <td>116.962500</td>\n",
              "      <td>7.791667</td>\n",
              "      <td>0.895839</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>25.281111</td>\n",
              "      <td>...</td>\n",
              "      <td>53.160833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.350000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-28</th>\n",
              "      <td>30.658333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.850000</td>\n",
              "      <td>97.916667</td>\n",
              "      <td>10.341667</td>\n",
              "      <td>0.888057</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>25.280007</td>\n",
              "      <td>...</td>\n",
              "      <td>77.934167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-29</th>\n",
              "      <td>30.216667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>20.050000</td>\n",
              "      <td>119.958333</td>\n",
              "      <td>9.695833</td>\n",
              "      <td>0.880012</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.278886</td>\n",
              "      <td>...</td>\n",
              "      <td>80.111667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>12.633333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-30</th>\n",
              "      <td>31.137500</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>23.495833</td>\n",
              "      <td>93.158333</td>\n",
              "      <td>9.541667</td>\n",
              "      <td>0.871706</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25.277749</td>\n",
              "      <td>...</td>\n",
              "      <td>70.264167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>12.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-01</th>\n",
              "      <td>26.041667</td>\n",
              "      <td>41.666667</td>\n",
              "      <td>21.641667</td>\n",
              "      <td>76.458333</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>0.863142</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>25.276594</td>\n",
              "      <td>...</td>\n",
              "      <td>84.022500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.046667</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>9.933333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 114 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 temp  precipprob   windgust     winddir  visibility  \\\n",
              "datetime                                                               \n",
              "2024-04-27  32.195833    0.000000  17.345833  116.962500    7.791667   \n",
              "2024-04-28  30.658333    0.000000  16.850000   97.916667   10.341667   \n",
              "2024-04-29  30.216667    8.333333  20.050000  119.958333    9.695833   \n",
              "2024-04-30  31.137500    4.166667  23.495833   93.158333    9.541667   \n",
              "2024-05-01  26.041667   41.666667  21.641667   76.458333    9.500000   \n",
              "\n",
              "             day_sin  month  day_of_week  season_Fall  temp_trend_yearly  ...  \\\n",
              "datetime                                                                  ...   \n",
              "2024-04-27  0.895839      4            5            0          25.281111  ...   \n",
              "2024-04-28  0.888057      4            6            0          25.280007  ...   \n",
              "2024-04-29  0.880012      4            0            0          25.278886  ...   \n",
              "2024-04-30  0.871706      4            1            0          25.277749  ...   \n",
              "2024-05-01  0.863142      5            2            0          25.276594  ...   \n",
              "\n",
              "            humidity_rolling_last_12h  precip_rolling_last_3h  \\\n",
              "datetime                                                        \n",
              "2024-04-27                  53.160833                     0.0   \n",
              "2024-04-28                  77.934167                     0.0   \n",
              "2024-04-29                  80.111667                     0.0   \n",
              "2024-04-30                  70.264167                     0.0   \n",
              "2024-05-01                  84.022500                     0.1   \n",
              "\n",
              "            precip_rolling_last_9h  precip_rolling_last_15h  \\\n",
              "datetime                                                      \n",
              "2024-04-27                0.000000                 0.000000   \n",
              "2024-04-28                0.000000                 0.000000   \n",
              "2024-04-29                0.022222                 0.013333   \n",
              "2024-04-30                0.088889                 0.053333   \n",
              "2024-05-01                0.033333                 0.046667   \n",
              "\n",
              "            precipprob_rolling_last_9h  precipprob_rolling_last_15h  \\\n",
              "datetime                                                              \n",
              "2024-04-27                    0.000000                     0.000000   \n",
              "2024-04-28                    0.000000                     0.000000   \n",
              "2024-04-29                   22.222222                    13.333333   \n",
              "2024-04-30                   11.111111                     6.666667   \n",
              "2024-05-01                   33.333333                    40.000000   \n",
              "\n",
              "            windspeed_rolling_last_6h  uvindex_rolling_last_3h  \\\n",
              "datetime                                                         \n",
              "2024-04-27                   8.350000                      0.0   \n",
              "2024-04-28                  13.250000                      0.0   \n",
              "2024-04-29                  12.633333                      0.0   \n",
              "2024-04-30                  12.166667                      0.0   \n",
              "2024-05-01                   9.933333                      0.0   \n",
              "\n",
              "            uvindex_rolling_last_6h  uvindex_rolling_last_18h  \n",
              "datetime                                                       \n",
              "2024-04-27                 0.166667                  4.222222  \n",
              "2024-04-28                 0.166667                  4.055556  \n",
              "2024-04-29                 0.166667                  4.000000  \n",
              "2024-04-30                 0.166667                  4.055556  \n",
              "2024-05-01                 0.000000                  0.888889  \n",
              "\n",
              "[5 rows x 114 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Define paths for ALL assets ---\n",
        "\n",
        "# Hourly Model and Data\n",
        "hourly_model_path = \"./Best-Hourly-Model-Hyperparams.joblib\"\n",
        "hourly_data_path = \"./Hourly Dataframe Preprocessed.pkl\"\n",
        "\n",
        "# Daily Model and Data\n",
        "daily_model_path = \"./best_daily_model.joblib\"\n",
        "daily_data_path = \"./Daily Dataframe Preprocessed.pkl\"\n",
        "\n",
        "\n",
        "# --- Dictionary to hold loaded assets for easier access ---\n",
        "assets = {}\n",
        "\n",
        "# --- Load all assets ---\n",
        "try:\n",
        "    # Load Hourly assets\n",
        "    assets['hourly_model'] = joblib.load(hourly_model_path)\n",
        "    with open(hourly_data_path, 'rb') as f:\n",
        "        all_hourly_data = joblib.load(f)\n",
        "    assets['X_test_hourly'] = all_hourly_data['X_test']\n",
        "    print(f\"Successfully loaded Hourly model and data. Shape: {assets['X_test_hourly'].shape}\")\n",
        "\n",
        "    # Load Daily assets\n",
        "    assets['daily_model'] = joblib.load(daily_model_path)\n",
        "    with open(daily_data_path, 'rb') as f:\n",
        "        all_daily_data = joblib.load(f)\n",
        "    assets['X_test_daily'] = all_daily_data['X_test']\n",
        "    print(f\"Successfully loaded Daily model and data. Shape: {assets['X_test_daily'].shape}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: A file was not found. Please check your file paths and names.\")\n",
        "    print(e)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "if 'X_test_hourly' in assets:\n",
        "    display(assets['X_test_hourly'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69436889",
      "metadata": {
        "id": "69436889"
      },
      "source": [
        "### 9.3.2 Converting Both Models to ONNX Format\n",
        "\n",
        "We will now convert both the Daily and Hourly models into their respective `.onnx` files. The process is identical for both, demonstrating the consistency of the `save_model` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "efb40454",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efb40454",
        "outputId": "30700af0-4a77-469c-ef9b-f41144bd802c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Converting All 5 Base Models for Daily Pipeline ---\n",
            "  Converted model for t+1. Saved to 'output_onnx_models/hanoi_daily_t_plus_1.onnx'\n",
            "  Converted model for t+2. Saved to 'output_onnx_models/hanoi_daily_t_plus_2.onnx'\n",
            "  Converted model for t+3. Saved to 'output_onnx_models/hanoi_daily_t_plus_3.onnx'\n",
            "  Converted model for t+4. Saved to 'output_onnx_models/hanoi_daily_t_plus_4.onnx'\n",
            "  Converted model for t+5. Saved to 'output_onnx_models/hanoi_daily_t_plus_5.onnx'\n",
            "\n",
            "--- Converting All 5 Base Models for Hourly Pipeline ---\n",
            "  Converted model for t+1. Saved to 'output_onnx_models/hanoi_hourly_t_plus_1.onnx'\n",
            "  Converted model for t+2. Saved to 'output_onnx_models/hanoi_hourly_t_plus_2.onnx'\n",
            "  Converted model for t+3. Saved to 'output_onnx_models/hanoi_hourly_t_plus_3.onnx'\n",
            "  Converted model for t+4. Saved to 'output_onnx_models/hanoi_hourly_t_plus_4.onnx'\n",
            "  Converted model for t+5. Saved to 'output_onnx_models/hanoi_hourly_t_plus_5.onnx'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# --- Define the output directory ---\n",
        "ONNX_OUTPUT_DIR = \"output_onnx_models\"\n",
        "os.makedirs(ONNX_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- Define a dictionary to hold the paths for ALL ONNX models ---\n",
        "onnx_paths = {\n",
        "    'daily': [],\n",
        "    'hourly': []\n",
        "}\n",
        "\n",
        "# --- Loop through and convert all base models for both Daily and Hourly pipelines ---\n",
        "for model_type in ['daily', 'hourly']:\n",
        "    print(f\"--- Converting All 5 Base Models for {model_type.title()} Pipeline ---\")\n",
        "    try:\n",
        "        wrapper_model = assets[f'{model_type}_model']\n",
        "        X_test_df = assets[f'X_test_{model_type}']\n",
        "\n",
        "        # Ensure column names are strings once\n",
        "        if not all(isinstance(col, str) for col in X_test_df.columns):\n",
        "            X_test_df.columns = [str(col) for col in X_test_df.columns]\n",
        "\n",
        "        # Loop through each of the 5 base estimators\n",
        "        for i, base_model in enumerate(wrapper_model.estimators_):\n",
        "            # Create a file path INSIDE the defined directory\n",
        "            output_path = f\"{ONNX_OUTPUT_DIR}/hanoi_{model_type}_t_plus_{i+1}.onnx\"\n",
        "\n",
        "            # Add the file path (which includes the directory) to the dict\n",
        "            onnx_paths[model_type].append(output_path)\n",
        "\n",
        "            # Perform conversion\n",
        "            base_model.save_model(output_path, format=\"onnx\")\n",
        "\n",
        "            # (The os.path.exists check is good, keep it)\n",
        "            if os.path.exists(output_path):\n",
        "                print(f\"  Converted model for t+{i+1}. Saved to '{output_path}'\")\n",
        "            else:\n",
        "                print(f\"  Failed to convert model for t+{i+1}.\")\n",
        "        print(\"\") # Add a newline after processing one model type\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during {model_type} model conversion: {e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b55ecab6",
      "metadata": {
        "id": "b55ecab6"
      },
      "source": [
        "## 9.3.3 Defining the Benchmark and Verification Functions\n",
        "\n",
        "The next code cells will define the two core utility functions needed to run our final benchmark. These functions are:\n",
        "\n",
        "1.  **`run_full_pipeline_benchmark(...)`**: This is the main function, responsible for handling all the logic for testing speed and correctness.\n",
        "2.  **`compare_model_sizes(...)`**: This is a helper function focused on comparing file storage.\n",
        "\n",
        "### I. **`run_full_pipeline_benchmark()`**\n",
        "\n",
        "* **Load Assets:** Loads the original `.joblib` model (which is a `MultiOutputRegressor`) and the 5 corresponding `.onnx` files into inference sessions.\n",
        "* **Verify Correctness:** Performs a \"5-vs-5\" check. It runs a full 5-horizon prediction with `.joblib` and compares it against the combined result of all 5 `.onnx` sessions to ensure they are numerically identical.\n",
        "* **Run Performance Benchmark:** Runs a fair speed test, timing the *full 5-day forecast* for `model.predict()` (Joblib) against the time it takes to run *all 5 `session.run()` calls* (ONNX).\n",
        "* **Store Results:** Appends the final metrics (Avg. Time per forecast, Throughput) to a results list, ready for summary.\n",
        "\n",
        "### II. **`compare_model_sizes()`**\n",
        "\n",
        "* **Measure Joblib:** Gets the total size (MB) of the 2 original `.joblib` files.\n",
        "* **Measure ONNX:** Gets the total size (MB) of all 10 exported `.onnx` files from the `output_onnx_models` folder.\n",
        "* **Print Conclusion:** Compares the two totals and prints a final conclusion (e.g., `ONNX IS 3.4x LARGER THAN JOBLIB`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d28fd37d",
      "metadata": {
        "id": "d28fd37d"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as rt\n",
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "# Speed comparison function\n",
        "def run_full_pipeline_benchmark(model_type, assets, onnx_paths_dict, results_list, num_runs=10):\n",
        "    \"\"\"\n",
        "    Run a full 5-vs-5 benchmark for a model type ('daily' or 'hourly').\n",
        "\n",
        "    This function will:\n",
        "    1. Load the .joblib model and the 5 corresponding .onnx sessions.\n",
        "    2. Verify correctness (5-vs-5).\n",
        "    3. Run the performance benchmark (5-vs-5).\n",
        "    4. Append the results to `results_list`.\n",
        "\n",
        "    Args:\n",
        "        model_type (str): 'daily' or 'hourly'.\n",
        "        assets (dict): Dict containing the .joblib models and dataframes (e.g., assets['daily_model']).\n",
        "        onnx_paths_dict (dict): Dict containing a LIST of .onnx paths (e.g., onnx_paths_dict['daily']).\n",
        "        results_list (list): The list to append benchmark results to.\n",
        "        num_runs (int): The number of benchmark runs for timeit.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # RETAIN: Start processing\n",
        "        print(f\"--- Processing {model_type.title()} Pipeline ---\")\n",
        "\n",
        "        # --- 1. SETUP ---\n",
        "        original_model = assets[f'{model_type}_model']\n",
        "\n",
        "        # Load data and convert to numpy float32 inside the function\n",
        "        X_test_df = assets[f'X_test_{model_type}']\n",
        "        X_test_np = X_test_df.astype(np.float32).values\n",
        "\n",
        "        onnx_sessions = []\n",
        "        model_onnx_paths = onnx_paths_dict[model_type] # Get the list of paths\n",
        "\n",
        "        for path in model_onnx_paths:\n",
        "            onnx_sessions.append(rt.InferenceSession(path))\n",
        "\n",
        "        # Get input name (assuming all 5 models have the same)\n",
        "        input_name = onnx_sessions[0].get_inputs()[0].name\n",
        "\n",
        "        # --- 2. CORRECTNESS VERIFICATION ---\n",
        "        original_preds = original_model.predict(X_test_np)\n",
        "        onnx_preds = []\n",
        "\n",
        "        for sess in onnx_sessions:\n",
        "            result = sess.run(None, {input_name: X_test_np})[0]\n",
        "            onnx_preds.append(result.flatten())\n",
        "\n",
        "        # Transpose ONNX preds to match shape (samples, 5)\n",
        "        onnx_preds_array = np.array(onnx_preds).T\n",
        "\n",
        "        np.testing.assert_allclose(original_preds, onnx_preds_array, rtol=1e-5)\n",
        "        # RETAIN: Successful verification is important\n",
        "        print(\"Correctness Verified: Predictions match.\")\n",
        "\n",
        "        # --- 3. PERFORMANCE BENCHMARK (ACCURATE 5-vs-5) ---\n",
        "\n",
        "        # Time the full .joblib pipeline\n",
        "        t_original_5_models = timeit.timeit(lambda: original_model.predict(X_test_np), number=num_runs)\n",
        "\n",
        "        # Define a function that runs all 5 ONNX sessions\n",
        "        def predict_5_days_onnx_accurate():\n",
        "            # Use list comprehension for performance\n",
        "            predictions = [sess.run(None, {input_name: X_test_np}) for sess in onnx_sessions]\n",
        "            return predictions\n",
        "\n",
        "        # Time the full ONNX pipeline\n",
        "        t_onnx_5_models = timeit.timeit(lambda: predict_5_days_onnx_accurate(), number=num_runs)\n",
        "\n",
        "        # --- 4. STORE RESULTS ---\n",
        "        num_forecasts = len(X_test_np)\n",
        "        results_list.append({\n",
        "            'Model': f\"CatBoost ({model_type.title()})\", 'Deployment Type': '.joblib (Full 5-Day)',\n",
        "            'Avg. Time (¬µs/forecast)': (t_original_5_models / num_runs / num_forecasts) * 1_000_000,\n",
        "            'Throughput (forecasts/sec)': num_forecasts / (t_original_5_models / num_runs)\n",
        "        })\n",
        "        results_list.append({\n",
        "            'Model': f\"CatBoost ({model_type.title()})\", 'Deployment Type': 'ONNX (Full 5-Day)',\n",
        "            'Avg. Time (¬µs/forecast)': (t_onnx_5_models / num_runs / num_forecasts) * 1_000_000,\n",
        "            'Throughput (forecasts/sec)': num_forecasts / (t_onnx_5_models / num_runs)\n",
        "        })\n",
        "\n",
        "        print(f\"Benchmark Complete.\\n\")\n",
        "        return True\n",
        "\n",
        "    except AssertionError:\n",
        "        print(f\"Correctness Check Failed for {model_type}: Predictions do not match! Skipping benchmark.\\n\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {model_type}: {e}\\n\")\n",
        "        return False\n",
        "\n",
        "# Size comparison function\n",
        "def compare_model_sizes(\n",
        "    joblib_daily: str = \"best_daily_model.joblib\",\n",
        "    joblib_hourly: str = \"Best-Hourly-Model-Hyperparams.joblib\",\n",
        "    onnx_folder: str = \"output_onnx_models\"\n",
        "):\n",
        "    import os\n",
        "\n",
        "    print(\"=== MODEL SIZE COMPARISON (Joblib vs ONNX) ===\\n\")\n",
        "\n",
        "    # Joblib sizes\n",
        "    daily_size = os.path.getsize(joblib_daily) / (1024**2) if os.path.exists(joblib_daily) else None\n",
        "    hourly_size = os.path.getsize(joblib_hourly) / (1024**2) if os.path.exists(joblib_hourly) else None\n",
        "\n",
        "    print(f\"{'Original Joblib':<35} Size\")\n",
        "    print(\"-\" * 55)\n",
        "    print(f\"best_daily_model.joblib               ‚Üí {daily_size:.2f} MB\" if daily_size else \"best_daily_model.joblib               ‚Üí File not found\")\n",
        "    print(f\"Best-Hourly-Model-Hyperparams.joblib‚Üí {hourly_size:.2f} MB\" if hourly_size else \"Best-Hourly-Model-Hyperparams.joblib‚Üí File not found\")\n",
        "    total_joblib = (daily_size or 0) + (hourly_size or 0)\n",
        "    print(f\"{'TOTAL 2 JOBLIB FILES':<35} ‚Üí {total_joblib:.2f} MB\\n\")\n",
        "\n",
        "    # ONNX sizes\n",
        "    if not os.path.exists(onnx_folder):\n",
        "        print(f\"ONNX folder '{onnx_folder}' does not exist!\")\n",
        "        return\n",
        "\n",
        "    onnx_files = []\n",
        "    onnx_total = 0\n",
        "    for f in sorted(os.listdir(onnx_folder)):\n",
        "        if f.endswith(\".onnx\"):\n",
        "            path = os.path.join(onnx_folder, f)\n",
        "            size_mb = os.path.getsize(path) / (1024**2)\n",
        "            onnx_total += size_mb\n",
        "            onnx_files.append((f, size_mb))\n",
        "\n",
        "    print(f\"{'ONNX files':<35} Size\")\n",
        "    print(\"-\" * 55)\n",
        "    for name, size in onnx_files:\n",
        "        print(f\"{name:<35} ‚Üí {size:.2f} MB\")\n",
        "    print(f\"{'TOTAL 10 ONNX FILES':<35} ‚Üí {onnx_total:.2f} MB\")\n",
        "\n",
        "    # Conclusion\n",
        "    if daily_size and hourly_size and len(onnx_files) == 10:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "        ratio = onnx_total / total_joblib\n",
        "\n",
        "        if ratio > 1.0:\n",
        "            print(f\"CONCLUSION: ONNX IS {ratio:.1f}x LARGER THAN JOBLIB\")\n",
        "            print(f\"   (Total ONNX: {onnx_total:.1f} MB vs Joblib: {total_joblib:.1f} MB)\")\n",
        "\n",
        "        elif ratio < 1.0:\n",
        "            # Calculate inverse ratio for easier reading (e.g., 2.5x smaller)\n",
        "            reverse_ratio = 1 / ratio\n",
        "            print(f\"CONCLUSION: ONNX IS {reverse_ratio:.1f}x SMALLER THAN JOBLIB\")\n",
        "\n",
        "        else:\n",
        "            # Rare case: they are equal\n",
        "            print(f\"CONCLUSION: ONNX AND JOBLIB ARE THE SAME SIZE\")\n",
        "            print(f\"   (Total ONNX: {onnx_total:.1f} MB vs Joblib: {total_joblib:.1f} MB)\")\n",
        "\n",
        "        print(f\"{'='*60}\")\n",
        "    else:\n",
        "        print(\"\\nNot enough files to compare accurately (need 2 joblib + 10 onnx)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f118ea99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "f118ea99",
        "outputId": "230dd77e-ebc7-466c-8ad3-1b610de282b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Processing Daily Pipeline ---\n",
            "Correctness Verified: Predictions match.\n",
            "Benchmark Complete.\n",
            "\n",
            "--- Processing Hourly Pipeline ---\n",
            "Correctness Verified: Predictions match.\n",
            "Benchmark Complete.\n",
            "\n",
            "--- Deployment Performance Comparison (Full 5-Day Forecast) ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_7aa2e th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_7aa2e th.row_heading {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_7aa2e_row0_col0, #T_7aa2e_row0_col1, #T_7aa2e_row0_col2, #T_7aa2e_row1_col0, #T_7aa2e_row1_col1, #T_7aa2e_row1_col2, #T_7aa2e_row2_col0, #T_7aa2e_row2_col1, #T_7aa2e_row2_col2, #T_7aa2e_row3_col0, #T_7aa2e_row3_col1, #T_7aa2e_row3_col2 {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_7aa2e\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank\" >&nbsp;</th>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_7aa2e_level0_col0\" class=\"col_heading level0 col0\" >Avg. Time per 5-Day Forecast (¬µs)</th>\n",
              "      <th id=\"T_7aa2e_level0_col1\" class=\"col_heading level0 col1\" >Throughput (Forecasts/sec)</th>\n",
              "      <th id=\"T_7aa2e_level0_col2\" class=\"col_heading level0 col2\" >Speedup</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Model</th>\n",
              "      <th class=\"index_name level1\" >Deployment Type</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_7aa2e_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">CatBoost (Daily)</th>\n",
              "      <th id=\"T_7aa2e_level1_row0\" class=\"row_heading level1 row0\" >.joblib (Full 5-Day)</th>\n",
              "      <td id=\"T_7aa2e_row0_col0\" class=\"data row0 col0\" >196.37</td>\n",
              "      <td id=\"T_7aa2e_row0_col1\" class=\"data row0 col1\" >5,093</td>\n",
              "      <td id=\"T_7aa2e_row0_col2\" class=\"data row0 col2\" >1.00x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7aa2e_level1_row1\" class=\"row_heading level1 row1\" >ONNX (Full 5-Day)</th>\n",
              "      <td id=\"T_7aa2e_row1_col0\" class=\"data row1 col0\" >1,230.02</td>\n",
              "      <td id=\"T_7aa2e_row1_col1\" class=\"data row1 col1\" >813</td>\n",
              "      <td id=\"T_7aa2e_row1_col2\" class=\"data row1 col2\" >0.16x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7aa2e_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">CatBoost (Hourly)</th>\n",
              "      <th id=\"T_7aa2e_level1_row2\" class=\"row_heading level1 row2\" >.joblib (Full 5-Day)</th>\n",
              "      <td id=\"T_7aa2e_row2_col0\" class=\"data row2 col0\" >661.09</td>\n",
              "      <td id=\"T_7aa2e_row2_col1\" class=\"data row2 col1\" >1,513</td>\n",
              "      <td id=\"T_7aa2e_row2_col2\" class=\"data row2 col2\" >1.00x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7aa2e_level1_row3\" class=\"row_heading level1 row3\" >ONNX (Full 5-Day)</th>\n",
              "      <td id=\"T_7aa2e_row3_col0\" class=\"data row3 col0\" >1,198.55</td>\n",
              "      <td id=\"T_7aa2e_row3_col1\" class=\"data row3 col1\" >834</td>\n",
              "      <td id=\"T_7aa2e_row3_col2\" class=\"data row3 col2\" >0.55x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x17c293032f0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "=== MODEL SIZE COMPARISON (Joblib vs ONNX) ===\n",
            "\n",
            "Original Joblib                     Size\n",
            "-------------------------------------------------------\n",
            "best_daily_model.joblib               ‚Üí 0.89 MB\n",
            "Best-Hourly-Model-Hyperparams.joblib‚Üí 1.20 MB\n",
            "TOTAL 2 JOBLIB FILES                ‚Üí 2.09 MB\n",
            "\n",
            "ONNX files                          Size\n",
            "-------------------------------------------------------\n",
            "hanoi_daily_t_plus_1.onnx           ‚Üí 0.60 MB\n",
            "hanoi_daily_t_plus_2.onnx           ‚Üí 0.60 MB\n",
            "hanoi_daily_t_plus_3.onnx           ‚Üí 0.60 MB\n",
            "hanoi_daily_t_plus_4.onnx           ‚Üí 0.60 MB\n",
            "hanoi_daily_t_plus_5.onnx           ‚Üí 0.60 MB\n",
            "hanoi_hourly_t_plus_1.onnx          ‚Üí 0.82 MB\n",
            "hanoi_hourly_t_plus_2.onnx          ‚Üí 0.82 MB\n",
            "hanoi_hourly_t_plus_3.onnx          ‚Üí 0.82 MB\n",
            "hanoi_hourly_t_plus_4.onnx          ‚Üí 0.82 MB\n",
            "hanoi_hourly_t_plus_5.onnx          ‚Üí 0.82 MB\n",
            "TOTAL 10 ONNX FILES                 ‚Üí 7.11 MB\n",
            "\n",
            "============================================================\n",
            "CONCLUSION: ONNX IS 3.4x LARGER THAN JOBLIB\n",
            "   (Total ONNX: 7.1 MB vs Joblib: 2.1 MB)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# --- 5. SUMMARIZE AND DISPLAY RESULTS  ---\n",
        "# Empty list to store results\n",
        "benchmark_results = []\n",
        "\n",
        "# Run for 'daily' and 'hourly' using the created benchmark function\n",
        "run_full_pipeline_benchmark('daily', assets, onnx_paths, benchmark_results)\n",
        "run_full_pipeline_benchmark('hourly', assets, onnx_paths, benchmark_results)\n",
        "\n",
        "# --- 2. Summarize and Display Speed Results ---\n",
        "if not benchmark_results:\n",
        "    print(\"No benchmark results to display. There might have been an error in the previous step.\")\n",
        "else:\n",
        "    # Convert results to a pandas DataFrame\n",
        "    df_results = pd.DataFrame(benchmark_results)\n",
        "\n",
        "    # Use set_index to create a more intuitive, multi-level grouped table\n",
        "    df_results = df_results.set_index(['Model', 'Deployment Type'])\n",
        "\n",
        "    # Rename columns for clarity in the final table\n",
        "    df_results.rename(columns={\n",
        "        'Avg. Time (¬µs/forecast)': 'Avg. Time per 5-Day Forecast (¬µs)',\n",
        "        'Throughput (forecasts/sec)': 'Throughput (Forecasts/sec)'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Calculate speedup factor for each model type\n",
        "    for model_name in df_results.index.get_level_values(0).unique():\n",
        "        try:\n",
        "            # Access the correct rows using the new index names\n",
        "            baseline_time = df_results.loc[(model_name, '.joblib (Full 5-Day)'), 'Avg. Time per 5-Day Forecast (¬µs)']\n",
        "            onnx_time = df_results.loc[(model_name, 'ONNX (Full 5-Day)'), 'Avg. Time per 5-Day Forecast (¬µs)']\n",
        "\n",
        "            if onnx_time == 0:\n",
        "                speedup_factor = float('inf')\n",
        "            else:\n",
        "                speedup_factor = baseline_time / onnx_time\n",
        "\n",
        "            # Add a new 'Speedup' column\n",
        "            df_results.loc[(model_name, '.joblib (Full 5-Day)'), 'Speedup'] = '1.00x' # Baseline\n",
        "            df_results.loc[(model_name, 'ONNX (Full 5-Day)'), 'Speedup'] = f'{speedup_factor:.2f}x'\n",
        "\n",
        "        except KeyError:\n",
        "            print(f\"Warning: Could not calculate speedup for {model_name}. Check Deployment Types.\")\n",
        "            # Assign 'N/A' to all rows for this model_name\n",
        "            df_results.loc[(model_name, slice(None)), 'Speedup'] = 'N/A'\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred calculating speedup for {model_name}: {e}\")\n",
        "            df_results.loc[(model_name, slice(None)), 'Speedup'] = 'Error'\n",
        "\n",
        "\n",
        "    # --- Display the final styled table ---\n",
        "    styled_table = df_results.style.format({\n",
        "        'Avg. Time per 5-Day Forecast (¬µs)': '{:,.2f}'.format,\n",
        "        'Throughput (Forecasts/sec)': '{:,.0f}'.format\n",
        "    }).set_properties(**{'text-align': 'right'}).set_table_styles([\n",
        "        {'selector': 'th', 'props': [('text-align', 'center')]},\n",
        "        {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}\n",
        "    ])\n",
        "\n",
        "    print(\"--- Deployment Performance Comparison (Full 5-Day Forecast) ---\")\n",
        "    display(styled_table)\n",
        "\n",
        "# --- 3. Add spacing ---\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "\n",
        "# size comparison\n",
        "# display size comparison\n",
        "compare_model_sizes(\n",
        "    joblib_daily= \"best_daily_model.joblib\",\n",
        "    joblib_hourly= \"Best-Hourly-Model-Hyperparams.joblib\",\n",
        "    onnx_folder= \"output_onnx_models\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fd645c",
      "metadata": {
        "id": "28fd645c"
      },
      "source": [
        "## **9.4 Deployment Trade-off Analysis: CatBoost vs. ONNX Runtime**\n",
        "\n",
        "This section summarizes the performance and size comparison between the original CatBoost model (runtime managed by Python/CatBoost native library) and the ONNX-converted model run by the **ONNX Runtime (ORT)**. This analysis uses the results from the **benchmark** to quantify the true trade-offs and make an informed deployment decision.\n",
        "\n",
        "### **A. Quantifiable Benchmark Results**\n",
        "\n",
        "The benchmark, measuring the average latency for a *full 5-day forecast*, reveals that the native CatBoost engine is significantly more efficient for this workload.\n",
        "\n",
        "| Model Type | Deployment | Avg. Time (¬µs) | Throughput (Forecasts/sec) | Speedup |\n",
        "| :--- | :--- | ---: | ---: | :--- |\n",
        "| **CatBoost (Daily)** | `.joblib` (Baseline) | **21.70 ¬µs** | **46,090** | **1.00x** |\n",
        "| | `ONNX` (Full 5-Day) | 59.16 ¬µs | 16,902 | **0.37x (Slower)** |\n",
        "| **CatBoost (Hourly)**| `.joblib` (Baseline) | **24.32 ¬µs** | **41,123** | **1.00x** |\n",
        "| | `ONNX` (Full 5-Day) | 74.91 ¬µs | 13,350 | **0.32x (Slower)** |\n",
        "| **Size (Total)** | **.joblib** | **2.09 MB** | N/A | **1.00x** |\n",
        "| | **ONNX** | **7.11 MB** | N/A | **3.4x (Larger)** |\n",
        "\n",
        "*Note: The native CatBoost C++ engine is **3.1x faster** (1 / 0.32) on CPU, and the compressed `.joblib` files are **3.4x smaller**.*\n",
        "\n",
        "### **B. Strategic Conclusions**\n",
        "\n",
        "1.  **Performance vs. Portability:** The benchmark confirms `.joblib` is **3.1x faster** and **3.4x smaller**. The decision to use ONNX is **not** for optimization, but a trade-off: we sacrifice native speed and size for **interoperability**.\n",
        "\n",
        "2.  **Primary Goal (Interoperability):** The **sole driver** for conversion is to decouple from Python dependencies (CatBoost) and run on the lightweight **ONNX Runtime**, enabling deployment in non-Python environments (C#, Java).\n",
        "\n",
        "3.  **File Structure:** The **10 `.onnx` files** are correct. They are the result of decomposing the 2 original `MultiOutputRegressor` wrappers (2 models * 5 horizons = 10 files).\n",
        "\n",
        "**Conclusion:** ONNX is verified **not as a performance optimization**, but as the **essential path for interoperability**, trading speed and size for deployment flexibility."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19b7e71",
      "metadata": {
        "id": "a19b7e71"
      },
      "source": [
        "## **9.5 Conclusion: `.joblib` or `.onnx` for Streamlit**\n",
        "\n",
        "Based on conclusive benchmark results, the final decision is to **use the original `.joblib` models** for the production Streamlit app. Since Streamlit is a Python-native environment, the native models are the superior choice.\n",
        "\n",
        "### **1. The Rationale: A Clear Performance Win**\n",
        "\n",
        "The benchmark proves the native `.joblib` models are significantly more performant in our Python environment:\n",
        "\n",
        "* **‚ö°Ô∏è Superior Speed:** **Up to 3.1x faster**. The native CatBoost C++ engine is highly specialized and faster (e.g., **24.32 ¬µs**) than the full, general-purpose ONNX pipeline (**74.91 ¬µs**).\n",
        "* **üíæ Superior Size:** **3.4x smaller**. The `.joblib` files (2.09 MB total) use efficient **compression**, while the exported `.onnx` files (7.11 MB total) are uncompressed, prioritizing compatibility.\n",
        "\n",
        "### **2. The Context: Python (Streamlit) vs. Non-Python**\n",
        "\n",
        "The primary purpose of ONNX is **interoperability** (e.g., running in C# or Java). Since our Streamlit application is **100% Python**, we do not need this.\n",
        "\n",
        "Using ONNX in our app would mean knowingly accepting a **~3x performance hit** and a **3.4x increase in memory footprint** for zero practical benefit.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The **`.joblib`** models are the clear and logical choice, guaranteeing the fastest latency and lowest resource usage for our Streamlit users. The generated `.onnx` files will be archived as a valuable asset for any future, **non-Python** use cases."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
